{"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":605,"status":"ok","timestamp":1717855831269,"user":{"displayName":"Mahdi Alipour","userId":"15525500010394253149"},"user_tz":-210},"id":"PPSAGC05IS31","outputId":"40bef8f8-cc28-4e03-bcf2-3abcaf67805e"},"outputs":[{"name":"stdout","output_type":"stream","text":["fatal: destination path 'Persian-Wikipedia-Dataset' already exists and is not an empty directory.\n","/content/Persian-Wikipedia-Dataset\n"]}],"source":["\n","!git clone https://github.com/malipourha/Persian-Wikipedia-Dataset.git\n","\n","\n","%cd Persian-Wikipedia-Dataset\n"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":550,"status":"ok","timestamp":1717855857270,"user":{"displayName":"Mahdi Alipour","userId":"15525500010394253149"},"user_tz":-210},"id":"WYg8vkS9IpFM","outputId":"378c2e30-8f66-49f4-ad66-69c788f50b47"},"outputs":[{"name":"stdout","output_type":"stream","text":["README.md\n"]}],"source":["!ls\n"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":902625,"status":"ok","timestamp":1717858746593,"user":{"displayName":"Mahdi Alipour","userId":"15525500010394253149"},"user_tz":-210},"id":"vgm8XsCfONZy","outputId":"74ea8a68-9754-4efc-9472-54ceb367708e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'Persian-Wikipedia-Dataset'...\n","remote: Enumerating objects: 27, done.\u001b[K\n","remote: Counting objects:   3% (1/27)\u001b[K\rremote: Counting objects:   7% (2/27)\u001b[K\rremote: Counting objects:  11% (3/27)\u001b[K\rremote: Counting objects:  14% (4/27)\u001b[K\rremote: Counting objects:  18% (5/27)\u001b[K\rremote: Counting objects:  22% (6/27)\u001b[K\rremote: Counting objects:  25% (7/27)\u001b[K\rremote: Counting objects:  29% (8/27)\u001b[K\rremote: Counting objects:  33% (9/27)\u001b[K\rremote: Counting objects:  37% (10/27)\u001b[K\rremote: Counting objects:  40% (11/27)\u001b[K\rremote: Counting objects:  44% (12/27)\u001b[K\rremote: Counting objects:  48% (13/27)\u001b[K\rremote: Counting objects:  51% (14/27)\u001b[K\rremote: Counting objects:  55% (15/27)\u001b[K\rremote: Counting objects:  59% (16/27)\u001b[K\rremote: Counting objects:  62% (17/27)\u001b[K\rremote: Counting objects:  66% (18/27)\u001b[K\rremote: Counting objects:  70% (19/27)\u001b[K\rremote: Counting objects:  74% (20/27)\u001b[K\rremote: Counting objects:  77% (21/27)\u001b[K\rremote: Counting objects:  81% (22/27)\u001b[K\rremote: Counting objects:  85% (23/27)\u001b[K\rremote: Counting objects:  88% (24/27)\u001b[K\rremote: Counting objects:  92% (25/27)\u001b[K\rremote: Counting objects:  96% (26/27)\u001b[K\rremote: Counting objects: 100% (27/27)\u001b[K\rremote: Counting objects: 100% (27/27), done.\u001b[K\n","remote: Compressing objects:   5% (1/17)\u001b[K\rremote: Compressing objects:  11% (2/17)\u001b[K\rremote: Compressing objects:  17% (3/17)\u001b[K\rremote: Compressing objects:  23% (4/17)\u001b[K\rremote: Compressing objects:  29% (5/17)\u001b[K\rremote: Compressing objects:  35% (6/17)\u001b[K\rremote: Compressing objects:  41% (7/17)\u001b[K\rremote: Compressing objects:  47% (8/17)\u001b[K\rremote: Compressing objects:  52% (9/17)\u001b[K\rremote: Compressing objects:  58% (10/17)\u001b[K\rremote: Compressing objects:  64% (11/17)\u001b[K\rremote: Compressing objects:  70% (12/17)\u001b[K\rremote: Compressing objects:  76% (13/17)\u001b[K\rremote: Compressing objects:  82% (14/17)\u001b[K\rremote: Compressing objects:  88% (15/17)\u001b[K\rremote: Compressing objects:  94% (16/17)\u001b[K\rremote: Compressing objects: 100% (17/17)\u001b[K\rremote: Compressing objects: 100% (17/17), done.\u001b[K\n","remote: Total 27 (delta 7), reused 0 (delta 0), pack-reused 0\u001b[K\n","Receiving objects:   3% (1/27)\rReceiving objects:   7% (2/27)\rReceiving objects:  11% (3/27)\rReceiving objects:  14% (4/27)\rReceiving objects:  18% (5/27)\rReceiving objects:  22% (6/27)\rReceiving objects:  25% (7/27)\rReceiving objects:  29% (8/27)\rReceiving objects:  33% (9/27)\rReceiving objects:  37% (10/27)\rReceiving objects:  40% (11/27)\rReceiving objects:  44% (12/27)\rReceiving objects:  48% (13/27)\rReceiving objects:  51% (14/27)\rReceiving objects:  55% (15/27)\rReceiving objects:  59% (16/27)\rReceiving objects:  62% (17/27)\rReceiving objects:  66% (18/27)\rReceiving objects:  70% (19/27)\rReceiving objects:  74% (20/27)\rReceiving objects:  77% (21/27)\rReceiving objects:  81% (22/27)\rReceiving objects:  85% (23/27)\rReceiving objects:  88% (24/27)\rReceiving objects:  92% (25/27)\rReceiving objects:  96% (26/27)\rReceiving objects: 100% (27/27)\rReceiving objects: 100% (27/27), 7.01 KiB | 7.01 MiB/s, done.\n","Resolving deltas:   0% (0/7)\rResolving deltas:  14% (1/7)\rResolving deltas:  28% (2/7)\rResolving deltas:  42% (3/7)\rResolving deltas:  57% (4/7)\rResolving deltas:  71% (5/7)\rResolving deltas:  85% (6/7)\rResolving deltas: 100% (7/7)\rResolving deltas: 100% (7/7), done.\n","/content/Persian-Wikipedia-Dataset/Persian-Wikipedia-Dataset/Persian-Wikipedia-Dataset/Persian-Wikipedia-Dataset\n","Epoch 1/10, Loss: 3.5830345153808594\n","Epoch 2/10, Loss: 3.0015032291412354\n","Epoch 3/10, Loss: 3.3557181358337402\n","Epoch 4/10, Loss: 2.387396812438965\n","Epoch 5/10, Loss: 1.6690555810928345\n","Epoch 6/10, Loss: 1.918216586112976\n","Epoch 7/10, Loss: 1.8043009042739868\n","Epoch 8/10, Loss: 1.148098111152649\n","Epoch 9/10, Loss: 1.2796820402145386\n","Epoch 10/10, Loss: 0.9654732942581177\n"]}],"source":["\n","!git clone https://github.com/malipourha/Persian-Wikipedia-Dataset.git\n","\n","\n","%cd Persian-Wikipedia-Dataset\n","\n","# Define file paths\n","file_paths = [\n","    'README.md'\n","]\n","\n","\n","import os\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","import re\n","from joblib import Parallel, delayed\n","\n","class PersianWikipediaDataset(Dataset):\n","    def __init__(self, file_paths, seq_length):\n","        self.text = self._read_files_in_parallel(file_paths)\n","        self.text = re.sub(r'\\s+', ' ', self.text)  \n","        self.vocab = sorted(set(self.text))\n","        self.vocab_size = len(self.vocab)\n","        self.char_to_idx = {char: idx for idx, char in enumerate(self.vocab)}\n","        self.idx_to_char = {idx: char for idx, char in enumerate(self.vocab)}\n","        self.seq_length = seq_length\n","        self.data = self._create_sequences()\n","\n","    def _read_files_in_parallel(self, file_paths):\n","        texts = Parallel(n_jobs=-1)(delayed(self._read_file)(file_path) for file_path in file_paths)\n","        return ''.join(texts)\n","\n","    def _read_file(self, file_path):\n","        with open(file_path, 'r', encoding='utf-8') as f:\n","            return f.read()\n","\n","    def _create_sequences(self):\n","        sequences = []\n","        next_chars = []\n","        for i in range(0, len(self.text) - self.seq_length):\n","            sequences.append(self.text[i:i + self.seq_length])\n","            next_chars.append(self.text[i + self.seq_length])\n","\n","        X = torch.zeros((len(sequences), self.seq_length), dtype=torch.long)\n","        y = torch.zeros((len(sequences),), dtype=torch.long)\n","\n","        for i, seq in enumerate(sequences):\n","            for j, char in enumerate(seq):\n","                X[i, j] = self.char_to_idx[char]\n","            y[i] = self.char_to_idx[next_chars[i]]\n","\n","        return X, y\n","\n","    def __len__(self):\n","        return len(self.data[0])\n","\n","    def __getitem__(self, idx):\n","        return self.data[0][idx], self.data[1][idx]\n","\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","class TextGenerationModel(nn.Module):\n","    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers):\n","        super(TextGenerationModel, self).__init__()\n","        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n","        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers, batch_first=True)\n","        self.fc = nn.Linear(hidden_dim, vocab_size)\n","\n","    def forward(self, x, hidden):\n","        x = self.embedding(x)\n","        out, hidden = self.lstm(x, hidden)\n","        out = self.fc(out[:, -1, :])\n","        return out, hidden\n","\n","    def init_hidden(self, batch_size):\n","        weight = next(self.parameters()).data\n","        return (weight.new(self.lstm.num_layers, batch_size, self.lstm.hidden_size).zero_(),\n","                weight.new(self.lstm.num_layers, batch_size, self.lstm.hidden_size).zero_())\n","\n","def train_model(model, dataloader, num_epochs, lr=0.001):\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = optim.Adam(model.parameters(), lr=lr)\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    model.to(device)\n","\n","    for epoch in range(num_epochs):\n","        hidden = model.init_hidden(dataloader.batch_size)\n","\n","        for inputs, targets in dataloader:\n","            batch_size = inputs.size(0)\n","            hidden = model.init_hidden(batch_size)  \n","            inputs, targets = inputs.to(device), targets.to(device)\n","            hidden = tuple([each.data for each in hidden])\n","\n","            model.zero_grad()\n","            output, hidden = model(inputs, hidden)\n","            loss = criterion(output, targets)\n","            loss.backward()\n","            optimizer.step()\n","\n","        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}')\n","\n","def split_files(file_paths, batch_size):\n","    for i in range(0, len(file_paths), batch_size):\n","        yield file_paths[i:i + batch_size]\n","\n","\n","batch_size = 2\n","seq_length = 100\n","num_epochs = 10\n","embedding_dim = 256\n","hidden_dim = 512\n","num_layers = 2\n","\n","\n","batches = list(split_files(file_paths, batch_size))\n","\n","\n","vocab_size = len(set(open(file_paths[0], 'r', encoding='utf-8').read()))\n","model = TextGenerationModel(vocab_size, embedding_dim, hidden_dim, num_layers)\n","\n","\n","for batch in batches:\n","    dataset = PersianWikipediaDataset(batch, seq_length)\n","    dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n","\n","    \n","    train_model(model, dataloader, num_epochs)\n"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":37934,"status":"ok","timestamp":1717859056749,"user":{"displayName":"Mahdi Alipour","userId":"15525500010394253149"},"user_tz":-210},"id":"-gw6LTAVYFGV","outputId":"d8e5a0c3-654b-48d4-cda1-c7b7a7ca42d0"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 31/31 [00:37<00:00,  1.21s/it]"]},{"name":"stdout","output_type":"stream","text":["Perplexity: 1.0076975704200648\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["import math\n","import numpy as np\n","from tqdm import tqdm\n","\n","def evaluate_perplexity(model, dataloader):\n","    model.eval()\n","    total_loss = 0.0\n","    total_words = 0\n","    criterion = nn.CrossEntropyLoss()\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    model.to(device)\n","\n","    with torch.no_grad():\n","        for inputs, targets in tqdm(dataloader):\n","            batch_size = inputs.size(0)\n","            hidden = model.init_hidden(batch_size)\n","            inputs, targets = inputs.to(device), targets.to(device)\n","            hidden = tuple([each.data for each in hidden])\n","\n","            output, hidden = model(inputs, hidden)\n","            loss = criterion(output, targets)\n","            total_loss += loss.item() * batch_size\n","            total_words += batch_size * inputs.size(1)\n","\n","    perplexity = math.exp(total_loss / total_words)\n","    return perplexity\n","\n","\n","test_dataloader = DataLoader(dataset, batch_size=64, shuffle=False)\n","perplexity = evaluate_perplexity(model, test_dataloader)\n","print(f'Perplexity: {perplexity}')\n"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":52919,"status":"ok","timestamp":1717859329981,"user":{"displayName":"Mahdi Alipour","userId":"15525500010394253149"},"user_tz":-210},"id":"IBN1mATXYv5c","outputId":"4b11b2f0-5a19-463a-ed8d-d5f35182c862"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting rouge-score\n","  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.4.0)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge-score) (3.8.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.25.2)\n","Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.16.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (2024.5.15)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (4.66.4)\n","Building wheels for collected packages: rouge-score\n","  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24933 sha256=974bb1487f3c9a71cd64ccacf3124223548685f016e6b5a465a219e76099d56f\n","  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n","Successfully built rouge-score\n","Installing collected packages: rouge-score\n","Successfully installed rouge-score-0.1.2\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 31/31 [00:39<00:00,  1.27s/it]"]},{"name":"stdout","output_type":"stream","text":["ROUGE Scores: {'rouge1': 0.18723793737818983, 'rouge2': 0.14229390681003581, 'rougeL': 0.18723793737818983}\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["\n","\n","from rouge_score import rouge_scorer\n","\n","def evaluate_rouge(model, dataloader, idx_to_char, num_samples=100):\n","    model.eval()\n","    generated_texts = []\n","    reference_texts = []\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    model.to(device)\n","\n","    with torch.no_grad():\n","        for inputs, targets in tqdm(dataloader):\n","            batch_size = inputs.size(0)\n","            hidden = model.init_hidden(batch_size)\n","            inputs, targets = inputs.to(device), targets.to(device)\n","            hidden = tuple([each.data for each in hidden])\n","\n","            output, hidden = model(inputs, hidden)\n","            output_indices = torch.argmax(output, dim=1).cpu().numpy()\n","            generated_texts.append(''.join([idx_to_char[idx] for idx in output_indices]))\n","            reference_texts.append(''.join([idx_to_char[idx] for idx in targets.cpu().numpy()]))\n","\n","            if len(generated_texts) >= num_samples:\n","                break\n","\n","    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n","    scores = []\n","    for gen_text, ref_text in zip(generated_texts, reference_texts):\n","        scores.append(scorer.score(ref_text, gen_text))\n","\n","    avg_scores = {metric: np.mean([score[metric].fmeasure for score in scores]) for metric in scores[0]}\n","    return avg_scores\n","\n","\n","rouge_scores = evaluate_rouge(model, test_dataloader, dataset.idx_to_char)\n","print(f'ROUGE Scores: {rouge_scores}')\n"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1072836,"status":"ok","timestamp":1717860579620,"user":{"displayName":"Mahdi Alipour","userId":"15525500010394253149"},"user_tz":-210},"id":"19ax-_NFZ2ar","outputId":"0c6c639e-1368-46b9-eeaa-90f27ad47140"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10, Loss: 1.0400390625\n","Epoch 2/10, Loss: 0.3503177762031555\n","Epoch 3/10, Loss: 0.49451297521591187\n","Epoch 4/10, Loss: 0.5274511575698853\n","Epoch 5/10, Loss: 0.31611064076423645\n","Epoch 6/10, Loss: 0.1544836163520813\n","Epoch 7/10, Loss: 0.07002132385969162\n","Epoch 8/10, Loss: 0.09672130644321442\n","Epoch 9/10, Loss: 0.07554357498884201\n","Epoch 10/10, Loss: 0.03580605983734131\n"]}],"source":["\n","persian_file_paths = [\n","    'README.md'\n","]\n","\n","num_epochs_finetuning = 10\n","\n","persian_dataset = PersianWikipediaDataset(persian_file_paths, seq_length)\n","persian_dataloader = DataLoader(persian_dataset, batch_size=64, shuffle=True)\n","\n","train_model(model, persian_dataloader, num_epochs_finetuning)\n"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":36621,"status":"ok","timestamp":1717860668933,"user":{"displayName":"Mahdi Alipour","userId":"15525500010394253149"},"user_tz":-210},"id":"0PA3vY9HePhh","outputId":"86580e12-5b52-4fac-a682-ebb5a6ffe198"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 31/31 [00:36<00:00,  1.18s/it]"]},{"name":"stdout","output_type":"stream","text":["Perplexity: 1.000416554036807\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["perplexity = evaluate_perplexity(model, persian_dataloader)\n","print(f'Perplexity: {perplexity}')\n"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":35840,"status":"ok","timestamp":1717860711678,"user":{"displayName":"Mahdi Alipour","userId":"15525500010394253149"},"user_tz":-210},"id":"cCen7KQNeaJ4","outputId":"3f0c8e4f-44ea-4ca3-8105-e1feef619568"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 31/31 [00:35<00:00,  1.15s/it]"]},{"name":"stdout","output_type":"stream","text":["ROUGE Scores: {'rouge1': 1.0, 'rouge2': 1.0, 'rougeL': 1.0}\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["rouge_scores = evaluate_rouge(model, persian_dataloader, persian_dataset.idx_to_char)\n","print(f'ROUGE Scores: {rouge_scores}')\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPjk6f+WVQhXLvEEDQnkKWx","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
