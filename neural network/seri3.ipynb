{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt \n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from copy import deepcopy\n",
    "import torch.optim as optim\n",
    "\n",
    "from tqdm.notebook import tqdm \n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>...</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "      <th>G3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>at_home</td>\n",
       "      <td>teacher</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>17</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>health</td>\n",
       "      <td>services</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>16</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  school sex  age address famsize Pstatus  Medu  Fedu     Mjob      Fjob  ...  \\\n",
       "0     GP   F   18       U     GT3       A     4     4  at_home   teacher  ...   \n",
       "1     GP   F   17       U     GT3       T     1     1  at_home     other  ...   \n",
       "2     GP   F   15       U     LE3       T     1     1  at_home     other  ...   \n",
       "3     GP   F   15       U     GT3       T     4     2   health  services  ...   \n",
       "4     GP   F   16       U     GT3       T     3     3    other     other  ...   \n",
       "\n",
       "  famrel freetime  goout  Dalc  Walc health absences  G1  G2  G3  \n",
       "0      4        3      4     1     1      3        4   0  11  11  \n",
       "1      5        3      3     1     1      3        2   9  11  11  \n",
       "2      4        3      2     2     3      3        6  12  13  12  \n",
       "3      3        2      2     1     1      5        0  14  14  14  \n",
       "4      4        3      2     1     2      5        0  11  13  13  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "file_path = \"/Users/asus/Desktop/term6/student-por.csv\" # write the path of your file\n",
    "df = pd.read_csv(file_path, header=0) \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "school        0\n",
       "sex           0\n",
       "age           0\n",
       "address       0\n",
       "famsize       0\n",
       "Pstatus       0\n",
       "Medu          0\n",
       "Fedu          0\n",
       "Mjob          0\n",
       "Fjob          0\n",
       "reason        0\n",
       "guardian      0\n",
       "traveltime    0\n",
       "studytime     0\n",
       "failures      0\n",
       "schoolsup     0\n",
       "famsup        0\n",
       "paid          0\n",
       "activities    0\n",
       "nursery       0\n",
       "higher        0\n",
       "internet      0\n",
       "romantic      0\n",
       "famrel        0\n",
       "freetime      0\n",
       "goout         0\n",
       "Dalc          0\n",
       "Walc          0\n",
       "health        0\n",
       "absences      0\n",
       "G1            0\n",
       "G2            0\n",
       "G3            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 649 entries, 0 to 648\n",
      "Data columns (total 33 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   school      649 non-null    object\n",
      " 1   sex         649 non-null    object\n",
      " 2   age         649 non-null    int64 \n",
      " 3   address     649 non-null    object\n",
      " 4   famsize     649 non-null    object\n",
      " 5   Pstatus     649 non-null    object\n",
      " 6   Medu        649 non-null    int64 \n",
      " 7   Fedu        649 non-null    int64 \n",
      " 8   Mjob        649 non-null    object\n",
      " 9   Fjob        649 non-null    object\n",
      " 10  reason      649 non-null    object\n",
      " 11  guardian    649 non-null    object\n",
      " 12  traveltime  649 non-null    int64 \n",
      " 13  studytime   649 non-null    int64 \n",
      " 14  failures    649 non-null    int64 \n",
      " 15  schoolsup   649 non-null    object\n",
      " 16  famsup      649 non-null    object\n",
      " 17  paid        649 non-null    object\n",
      " 18  activities  649 non-null    object\n",
      " 19  nursery     649 non-null    object\n",
      " 20  higher      649 non-null    object\n",
      " 21  internet    649 non-null    object\n",
      " 22  romantic    649 non-null    object\n",
      " 23  famrel      649 non-null    int64 \n",
      " 24  freetime    649 non-null    int64 \n",
      " 25  goout       649 non-null    int64 \n",
      " 26  Dalc        649 non-null    int64 \n",
      " 27  Walc        649 non-null    int64 \n",
      " 28  health      649 non-null    int64 \n",
      " 29  absences    649 non-null    int64 \n",
      " 30  G1          649 non-null    int64 \n",
      " 31  G2          649 non-null    int64 \n",
      " 32  G3          649 non-null    int64 \n",
      "dtypes: int64(16), object(17)\n",
      "memory usage: 167.4+ KB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "school         2\n",
       "sex            2\n",
       "age            8\n",
       "address        2\n",
       "famsize        2\n",
       "Pstatus        2\n",
       "Medu           5\n",
       "Fedu           5\n",
       "Mjob           5\n",
       "Fjob           5\n",
       "reason         4\n",
       "guardian       3\n",
       "traveltime     4\n",
       "studytime      4\n",
       "failures       4\n",
       "schoolsup      2\n",
       "famsup         2\n",
       "paid           2\n",
       "activities     2\n",
       "nursery        2\n",
       "higher         2\n",
       "internet       2\n",
       "romantic       2\n",
       "famrel         5\n",
       "freetime       5\n",
       "goout          5\n",
       "Dalc           5\n",
       "Walc           5\n",
       "health         5\n",
       "absences      24\n",
       "G1            17\n",
       "G2            16\n",
       "G3            17\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>traveltime</th>\n",
       "      <th>studytime</th>\n",
       "      <th>failures</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "      <th>G3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>649.000000</td>\n",
       "      <td>649.000000</td>\n",
       "      <td>649.000000</td>\n",
       "      <td>649.000000</td>\n",
       "      <td>649.000000</td>\n",
       "      <td>649.000000</td>\n",
       "      <td>649.000000</td>\n",
       "      <td>649.000000</td>\n",
       "      <td>649.000000</td>\n",
       "      <td>649.000000</td>\n",
       "      <td>649.000000</td>\n",
       "      <td>649.000000</td>\n",
       "      <td>649.000000</td>\n",
       "      <td>649.000000</td>\n",
       "      <td>649.000000</td>\n",
       "      <td>649.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>16.744222</td>\n",
       "      <td>2.514638</td>\n",
       "      <td>2.306626</td>\n",
       "      <td>1.568567</td>\n",
       "      <td>1.930663</td>\n",
       "      <td>0.221880</td>\n",
       "      <td>3.930663</td>\n",
       "      <td>3.180277</td>\n",
       "      <td>3.184900</td>\n",
       "      <td>1.502311</td>\n",
       "      <td>2.280431</td>\n",
       "      <td>3.536210</td>\n",
       "      <td>3.659476</td>\n",
       "      <td>11.399076</td>\n",
       "      <td>11.570108</td>\n",
       "      <td>11.906009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.218138</td>\n",
       "      <td>1.134552</td>\n",
       "      <td>1.099931</td>\n",
       "      <td>0.748660</td>\n",
       "      <td>0.829510</td>\n",
       "      <td>0.593235</td>\n",
       "      <td>0.955717</td>\n",
       "      <td>1.051093</td>\n",
       "      <td>1.175766</td>\n",
       "      <td>0.924834</td>\n",
       "      <td>1.284380</td>\n",
       "      <td>1.446259</td>\n",
       "      <td>4.640759</td>\n",
       "      <td>2.745265</td>\n",
       "      <td>2.913639</td>\n",
       "      <td>3.230656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>22.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age        Medu        Fedu  traveltime   studytime    failures  \\\n",
       "count  649.000000  649.000000  649.000000  649.000000  649.000000  649.000000   \n",
       "mean    16.744222    2.514638    2.306626    1.568567    1.930663    0.221880   \n",
       "std      1.218138    1.134552    1.099931    0.748660    0.829510    0.593235   \n",
       "min     15.000000    0.000000    0.000000    1.000000    1.000000    0.000000   \n",
       "25%     16.000000    2.000000    1.000000    1.000000    1.000000    0.000000   \n",
       "50%     17.000000    2.000000    2.000000    1.000000    2.000000    0.000000   \n",
       "75%     18.000000    4.000000    3.000000    2.000000    2.000000    0.000000   \n",
       "max     22.000000    4.000000    4.000000    4.000000    4.000000    3.000000   \n",
       "\n",
       "           famrel    freetime       goout        Dalc        Walc      health  \\\n",
       "count  649.000000  649.000000  649.000000  649.000000  649.000000  649.000000   \n",
       "mean     3.930663    3.180277    3.184900    1.502311    2.280431    3.536210   \n",
       "std      0.955717    1.051093    1.175766    0.924834    1.284380    1.446259   \n",
       "min      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "25%      4.000000    3.000000    2.000000    1.000000    1.000000    2.000000   \n",
       "50%      4.000000    3.000000    3.000000    1.000000    2.000000    4.000000   \n",
       "75%      5.000000    4.000000    4.000000    2.000000    3.000000    5.000000   \n",
       "max      5.000000    5.000000    5.000000    5.000000    5.000000    5.000000   \n",
       "\n",
       "         absences          G1          G2          G3  \n",
       "count  649.000000  649.000000  649.000000  649.000000  \n",
       "mean     3.659476   11.399076   11.570108   11.906009  \n",
       "std      4.640759    2.745265    2.913639    3.230656  \n",
       "min      0.000000    0.000000    0.000000    0.000000  \n",
       "25%      0.000000   10.000000   10.000000   10.000000  \n",
       "50%      2.000000   11.000000   11.000000   12.000000  \n",
       "75%      6.000000   13.000000   13.000000   14.000000  \n",
       "max     32.000000   19.000000   19.000000   19.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    school sex  age address famsize Pstatus  Medu  Fedu      Mjob      Fjob  \\\n",
      "0       GP   F   18       U     GT3       A     4     4   at_home   teacher   \n",
      "1       GP   F   17       U     GT3       T     1     1   at_home     other   \n",
      "2       GP   F   15       U     LE3       T     1     1   at_home     other   \n",
      "3       GP   F   15       U     GT3       T     4     2    health  services   \n",
      "4       GP   F   16       U     GT3       T     3     3     other     other   \n",
      "..     ...  ..  ...     ...     ...     ...   ...   ...       ...       ...   \n",
      "644     MS   F   19       R     GT3       T     2     3  services     other   \n",
      "645     MS   F   18       U     LE3       T     3     1   teacher  services   \n",
      "646     MS   F   18       U     GT3       T     1     1     other     other   \n",
      "647     MS   M   17       U     LE3       T     3     1  services  services   \n",
      "648     MS   M   18       R     LE3       T     3     2  services     other   \n",
      "\n",
      "     ... famrel freetime  goout  Dalc  Walc health absences  G1  G2  G3  \n",
      "0    ...      4        3      4     1     1      3        4   0  11  11  \n",
      "1    ...      5        3      3     1     1      3        2   9  11  11  \n",
      "2    ...      4        3      2     2     3      3        6  12  13  12  \n",
      "3    ...      3        2      2     1     1      5        0  14  14  14  \n",
      "4    ...      4        3      2     1     2      5        0  11  13  13  \n",
      "..   ...    ...      ...    ...   ...   ...    ...      ...  ..  ..  ..  \n",
      "644  ...      5        4      2     1     2      5        4  10  11  10  \n",
      "645  ...      4        3      4     1     1      1        4  15  15  16  \n",
      "646  ...      1        1      1     1     1      5        6  11  12   9  \n",
      "647  ...      2        4      5     3     4      2        6  10  10  10  \n",
      "648  ...      4        4      1     3     4      5        4  10  11  11  \n",
      "\n",
      "[649 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)\n",
    "for column in df.columns:\n",
    "    df[column], _ = pd.factorize(df[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>...</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "      <th>G3</th>\n",
       "      <th>total score</th>\n",
       "      <th>average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   school  sex  age  address  famsize  Pstatus  Medu  Fedu  Mjob  Fjob  ...  \\\n",
       "0       0    0    0        0        0        0     0     0     0     0  ...   \n",
       "1       0    0    1        0        0        1     1     1     0     1  ...   \n",
       "2       0    0    2        0        1        1     1     1     0     1  ...   \n",
       "3       0    0    2        0        0        1     0     2     1     2  ...   \n",
       "4       0    0    3        0        0        1     2     3     2     1  ...   \n",
       "\n",
       "   goout  Dalc  Walc  health  absences  G1  G2  G3  total score   average  \n",
       "0      0     0     0       0         0   0   0   0            0  0.000000  \n",
       "1      1     0     0       0         1   1   0   0            1  0.333333  \n",
       "2      2     1     1       0         2   2   1   1            4  1.333333  \n",
       "3      2     0     0       1         3   3   2   2            7  2.333333  \n",
       "4      2     0     2       1         3   4   1   3            8  2.666667  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['total score'] = df['G1'] + df['G2'] + df['G3']\n",
    "df['average'] = df['total score']/3\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['average']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.000000\n",
       "1      0.333333\n",
       "2      1.333333\n",
       "3      2.333333\n",
       "4      2.666667\n",
       "         ...   \n",
       "644    4.333333\n",
       "645    7.666667\n",
       "646    5.333333\n",
       "647    6.666667\n",
       "648    2.000000\n",
       "Name: average, Length: 649, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['average'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>...</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "      <th>G3</th>\n",
       "      <th>total score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   school  sex  age  address  famsize  Pstatus  Medu  Fedu  Mjob  Fjob  ...  \\\n",
       "0       0    0    0        0        0        0     0     0     0     0  ...   \n",
       "1       0    0    1        0        0        1     1     1     0     1  ...   \n",
       "2       0    0    2        0        1        1     1     1     0     1  ...   \n",
       "3       0    0    2        0        0        1     0     2     1     2  ...   \n",
       "4       0    0    3        0        0        1     2     3     2     1  ...   \n",
       "\n",
       "   freetime  goout  Dalc  Walc  health  absences  G1  G2  G3  total score  \n",
       "0         0      0     0     0       0         0   0   0   0            0  \n",
       "1         0      1     0     0       0         1   1   0   0            1  \n",
       "2         0      2     1     1       0         2   2   1   1            4  \n",
       "3         1      2     0     0       1         3   3   2   2            7  \n",
       "4         0      2     0     2       1         3   4   1   3            8  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.values\n",
    "y = y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((519, 34), (130, 34))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.FloatTensor(X_train)\n",
    "X_test = torch.FloatTensor(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  0.,  0.,  ..., 12., 11., 34.],\n",
       "        [ 0.,  1.,  3.,  ...,  0.,  1.,  3.],\n",
       "        [ 0.,  1.,  0.,  ...,  0.,  1.,  7.],\n",
       "        ...,\n",
       "        [ 0.,  1.,  3.,  ...,  8.,  5., 16.],\n",
       "        [ 1.,  0.,  2.,  ...,  7.,  7., 20.],\n",
       "        [ 0.,  1.,  2.,  ...,  1.,  1.,  4.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = torch.LongTensor(y_train)\n",
    "y_test = torch.LongTensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11,  1,  2,  2,  4,  3,  7,  8, 13,  3,  4,  2,  2,  5,  5, 10,  3,  3,\n",
       "         6,  1,  7,  7,  7,  5,  3,  6,  3,  5,  2,  2,  3,  5,  7,  3,  5,  5,\n",
       "         2,  9, 13,  2,  4,  2,  3,  3, 10,  6, 10,  6, 11,  3,  3,  7,  3,  0,\n",
       "         6,  0,  6,  8,  2,  3,  8,  9,  1,  7,  2,  5,  2,  2,  2,  3,  3,  7,\n",
       "         9,  3,  7,  1,  5,  8,  2,  3,  6,  2,  1,  2,  5,  7,  8,  0,  3,  1,\n",
       "         5,  1,  4,  3,  3,  5,  3,  5,  6,  0,  3,  1,  3, 11,  5,  3,  0,  4,\n",
       "         7,  5,  2,  2,  4,  1,  7,  8,  5,  0,  5,  2,  3, 10,  7,  8,  1,  0,\n",
       "         4,  2,  2,  6,  4,  3,  3,  3,  2,  5,  3,  8,  4, 13,  6,  9,  5,  3,\n",
       "         2,  4,  0,  0, 10,  5,  8,  9,  3, 11,  9,  1,  2,  5,  2,  9,  5,  1,\n",
       "         2,  6,  4,  5,  3,  2,  5,  4,  2,  2,  4,  5,  9,  2,  4,  7,  3,  2,\n",
       "         7,  3,  5,  8,  3,  3,  3,  4, 10,  3,  2,  2,  4,  5, 11,  9, 10,  2,\n",
       "         2,  2,  5,  9,  2,  3,  5,  3,  2,  9,  4,  6,  2,  3,  1,  3,  3,  2,\n",
       "         8,  9,  2,  4,  3,  6,  7,  8, 11,  9,  2,  3,  2,  2, 13,  1,  7,  2,\n",
       "         9,  8,  0,  3,  2,  9,  4,  9,  0,  2,  2,  3,  6, 10,  6,  3,  1,  6,\n",
       "         6,  2,  1,  5, 12,  6,  3,  7,  1,  1,  5,  7,  2,  4,  6,  4,  3,  2,\n",
       "         6,  8,  1,  3,  5,  6,  6,  4,  5,  5,  3,  4,  6, 11,  2,  2, 11,  2,\n",
       "         6,  5,  4,  6,  5,  8,  4,  5,  3,  2,  7,  3,  3,  2,  7,  0,  0,  8,\n",
       "         4,  2,  3,  6,  4, 11,  3,  4,  4,  3,  6,  1,  2,  6,  3,  2,  3,  9,\n",
       "         1, 14,  9, 11,  6,  3,  6,  2,  2,  3,  3,  9,  3, 11,  4,  6,  8,  5,\n",
       "         3,  6,  5,  6,  2,  2,  6,  6,  9,  4,  7,  9,  3,  2,  9, 12,  3,  8,\n",
       "         3,  3,  3,  2,  6,  9,  5,  2,  3,  4,  2,  2,  3,  3,  2,  7,  4,  2,\n",
       "        10,  8,  2,  6,  2,  4,  7,  4, 10,  1,  6,  2,  3,  1,  2,  3, 10,  1,\n",
       "         3,  2,  2,  1,  3,  8,  3,  1,  2,  2,  3,  6,  3,  2,  4,  2,  3,  7,\n",
       "         5,  4,  5,  3,  1,  6,  6,  8,  8,  2,  3,  2,  2,  0,  4,  1,  3,  2,\n",
       "         9,  3,  3,  2,  3,  7,  6,  2,  5,  8, 10,  2,  5,  3,  5,  5,  3,  5,\n",
       "         6,  3,  2,  7,  6,  7,  5,  0, 13,  7,  1,  1,  2,  8,  6,  5,  2,  2,\n",
       "         5,  6,  5,  2,  2,  3,  1,  4,  1,  4,  9, 10,  3,  2,  7,  6,  2,  2,\n",
       "         1,  5,  2,  2,  7,  2,  2,  3,  7,  1,  6,  6,  7,  5,  9,  6,  2,  2,\n",
       "         2,  2,  6,  5,  1,  3,  5,  2,  2,  1,  6,  6,  5,  6,  1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, num_inputs=34, num_hidden=649, num_2=649, num_output=15, dropout_rate=0.5, weight_decay=0.01):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(num_inputs, num_hidden)\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "        self.fc2 = nn.Linear(num_hidden, num_2)\n",
    "        self.dropout2 = nn.Dropout(dropout_rate)\n",
    "        self.out = nn.Linear(num_2, num_output)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(41)\n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.01, weight_decay=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "unique_labels = torch.unique(y_train)\n",
    "\n",
    "\n",
    "for i, label in enumerate(unique_labels):\n",
    "    y_train = torch.where(y_train == label, i, y_train)\n",
    "    y_test = torch.where(y_test == label, i, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0 and loss = 3.1393706798553467\n",
      "epoch10 and loss = 1.9962482452392578\n",
      "epoch20 and loss = 1.4737821817398071\n",
      "epoch30 and loss = 1.1266535520553589\n",
      "epoch40 and loss = 1.0313643217086792\n",
      "epoch50 and loss = 0.9481154680252075\n",
      "epoch60 and loss = 0.8813193440437317\n",
      "epoch70 and loss = 0.8374524712562561\n",
      "epoch80 and loss = 0.8283032178878784\n",
      "epoch90 and loss = 0.7844775319099426\n",
      "epoch100 and loss = 0.7760350704193115\n",
      "epoch110 and loss = 0.7638183236122131\n",
      "epoch120 and loss = 0.7038099765777588\n",
      "epoch130 and loss = 0.678835391998291\n",
      "epoch140 and loss = 0.6955588459968567\n",
      "epoch150 and loss = 0.6658716201782227\n",
      "epoch160 and loss = 0.6728125214576721\n",
      "epoch170 and loss = 0.6857091188430786\n",
      "epoch180 and loss = 0.6490954160690308\n",
      "epoch190 and loss = 0.6372958421707153\n"
     ]
    }
   ],
   "source": [
    "\n",
    "epochs = 200\n",
    "losses = []\n",
    "for i in range(epochs):\n",
    "\n",
    "    y_pred = model.forward(X_train) \n",
    "\n",
    "    loss = criterion(y_pred , y_train)\n",
    "\n",
    "    #losses.append(loss.detach().numpy())\n",
    "    losses.append(loss.item())\n",
    "    if i % 10 == 0:\n",
    "        print(f'epoch{i} and loss = {loss}')\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'epoch')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(epochs), losses)\n",
    "plt.ylabel(\"eror\")\n",
    "plt.xlabel(\"epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    y_eval = model.forward(X_test)\n",
    "    loss = criterion(y_eval, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.3661)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. tensor([-1.2489, -0.9726, -3.6324, -5.5912, -6.1211, -7.5420, -4.5402,  1.5200,\n",
      "         3.6079,  4.8313,  7.5893,  7.5896,  7.1352,  8.0521,  4.5078]) \t 12\n",
      "2. tensor([ 5.1256,  9.4351,  9.2935,  0.5158, -0.6228, -1.4177, -4.8475, -1.0652,\n",
      "        -2.9455, -0.6398, -1.8036, -1.2859, -1.6505, -2.2049, -1.9643]) \t 1\n",
      "3. tensor([-2.6152, -2.7661, -7.6913, -5.4746, -6.3895, -3.3930,  1.4305,  4.1277,\n",
      "         7.4382,  7.6371,  8.8471,  7.9424,  4.5873,  6.2230,  3.3436]) \t 11\n",
      "4. tensor([-2.1763,  4.6893,  5.9241,  3.7128,  3.9230,  2.8610, -2.0822, -1.8766,\n",
      "        -1.7846, -1.5111, -1.6094, -1.8725, -1.8886, -2.4975, -2.1458]) \t 2\n",
      "5. tensor([ 3.4650,  7.7369,  9.8480,  4.2376, -2.6406, -4.7991, -3.1056, -0.8926,\n",
      "        -2.2783, -0.7285, -1.7013, -1.6087, -1.5523, -2.3615, -1.9204]) \t 1\n",
      "6. tensor([-3.6555, -1.9514, -1.2982,  2.4281,  4.2650,  6.0137,  3.9448,  0.3665,\n",
      "         1.8305, -1.0797,  0.3031, -1.5305, -1.6795, -2.4109, -1.9125]) \t 6\n",
      "7. tensor([-2.2013, -2.6112, -6.5419, -5.3305, -3.8174, -0.8268,  3.0927,  4.5594,\n",
      "         5.6506,  5.1585,  4.6345,  4.4042,  1.6110,  2.3061,  1.9523]) \t 8\n",
      "8. tensor([-1.3264, -1.2944, -2.1498, -2.3952, -3.4015, -1.1980,  1.5424,  3.3011,\n",
      "         1.7604,  2.5518,  3.0352,  1.9830,  1.7158,  1.2016,  1.0237]) \t 8\n",
      "9. tensor([-2.7082, -2.1263, -1.4355,  0.5261,  1.0598,  3.2256,  4.4150,  4.0411,\n",
      "         1.7493,  1.4008,  0.7557,  0.2241, -1.0513, -2.1142, -1.4063]) \t 6\n",
      "10. tensor([-3.0611, -2.4970, -2.2985,  2.8447,  4.7348,  5.8347,  3.9364,  0.8192,\n",
      "         3.0317,  0.0924,  0.1199, -1.7067, -2.4535, -3.6118, -2.3971]) \t 3\n",
      "11. tensor([-2.5532, -2.8561, -8.1360, -6.7856, -7.2686, -0.8637,  1.2751,  3.7922,\n",
      "         6.4227,  7.0258,  7.8040,  7.5780,  5.0105,  5.7756,  4.3578]) \t 11\n",
      "12. tensor([-0.3846,  3.9808,  7.5560,  4.9098,  0.6317, -1.8946, -2.7156, -0.6262,\n",
      "        -2.2620, -0.7045, -1.5904, -1.5649, -1.4433, -2.1572, -1.7048]) \t 2\n",
      "13. tensor([ 0.9628,  6.5190, 11.3918,  5.9434,  3.1763, -1.7363, -2.9032, -2.1124,\n",
      "        -3.1161, -2.4441, -2.8663, -3.8396, -2.6946, -3.9514, -3.3552]) \t 2\n",
      "14. tensor([-2.2634, -1.5052, -3.1324, -1.8396, -1.6083, -0.2999,  3.4823,  6.1316,\n",
      "         2.9873,  1.7376,  4.0843,  2.5587,  0.4889,  0.7751,  0.4052]) \t 8\n",
      "15. tensor([ 7.5317, 10.7138, 10.0657,  2.0381, -3.6789, -6.4533, -6.1401, -2.2320,\n",
      "        -2.1989, -0.6805, -1.3678, -0.9954, -1.3787, -1.7966, -1.7184]) \t 1\n",
      "16. tensor([-3.4736,  1.4704,  6.6295,  7.4722,  3.8649,  1.7684, -0.0400, -1.1804,\n",
      "        -1.1156, -1.3820, -3.1208, -3.5435, -2.7705, -4.2488, -3.0115]) \t 2\n",
      "17. tensor([-2.0104,  2.2464,  7.7175,  4.2318,  2.3985,  1.0463, -0.7423, -1.7599,\n",
      "        -1.8332, -0.6150, -2.4199, -2.5098, -1.7295, -2.9025, -2.1837]) \t 1\n",
      "18. tensor([-3.4188, -3.3340, -4.5107, -7.1197, -8.2228,  0.0229,  3.7396,  7.0216,\n",
      "         5.1401,  6.2714,  5.7795,  4.8290,  2.9714,  2.6511,  1.2586]) \t 9\n",
      "19. tensor([-2.5002, -2.9750, -4.9935, -2.1226, -0.9671,  4.3112,  5.6879,  3.3438,\n",
      "         4.6385,  1.5360,  2.7109,  0.3646, -0.3642, -0.9494, -1.0828]) \t 6\n",
      "20. tensor([ 2.4117,  6.7141,  9.5650,  4.0800, -2.9586, -4.7450, -2.8656, -1.0098,\n",
      "        -2.1357, -1.2894, -1.4437, -1.8529, -1.4669, -2.3294, -1.9269]) \t 2\n",
      "21. tensor([-4.8042, -2.1508, -0.6669,  1.8560,  3.4090,  7.0136,  7.9061,  3.3458,\n",
      "         0.5118, -0.3962, -2.0277, -3.2304, -2.2578, -4.2017, -2.8778]) \t 5\n",
      "22. tensor([ 4.7457, 10.3770, 10.9711,  2.4219, -2.0959, -0.3562, -3.1456, -1.8363,\n",
      "        -3.2774, -1.4301, -2.1337, -2.9583, -2.0036, -3.0241, -2.7662]) \t 2\n",
      "23. tensor([-1.5921,  3.1149,  6.3231,  5.2285,  3.5690,  0.0122, -0.3522, -0.3230,\n",
      "        -1.2276, -1.9203, -2.3549, -2.6323, -2.4411, -3.2592, -2.4199]) \t 2\n",
      "24. tensor([-4.3384, -1.7773,  1.8650,  5.8631,  6.4308,  3.6263,  3.5788,  1.4586,\n",
      "         0.7945, -0.5145, -2.5461, -2.4446, -3.1235, -4.7310, -3.2570]) \t 3\n",
      "25. tensor([-3.9571, -2.1145,  1.7300,  0.9989,  2.2313,  3.9307,  4.5321,  5.8411,\n",
      "        -0.9621,  0.9527,  0.1567, -1.4553, -0.7078, -3.0188, -2.0777]) \t 6\n",
      "26. tensor([-0.9894,  1.2294,  3.6347,  5.2635,  1.1631,  0.2920,  0.0853, -0.4704,\n",
      "        -0.8555, -0.9320, -1.8908, -1.8570, -1.8811, -2.7150, -1.8894]) \t 2\n",
      "27. tensor([-6.2180, -1.1100,  0.8441,  0.0337,  5.3225,  9.9649,  4.5471, -0.6302,\n",
      "         1.5358,  2.1221, -0.8046, -1.5719, -1.8045, -3.5756, -2.5225]) \t 5\n",
      "28. tensor([ 4.3336,  8.5551,  9.4122,  1.5940, -0.5923, -2.7600, -3.7069, -1.6442,\n",
      "        -2.5802, -0.7656, -1.2618, -1.5270, -1.3846, -2.3278, -1.9934]) \t 2\n",
      "29. tensor([-4.2448, -0.4094,  0.5842,  5.7855,  7.0403,  5.2397,  0.2250, -0.7653,\n",
      "         0.4019, -0.5272, -1.6778, -1.9735, -2.6177, -3.4725, -2.5697]) \t 3\n",
      "30. tensor([-2.4218, -2.0967, -2.9608, -0.8806, -0.3435,  2.3960,  4.9574,  3.5410,\n",
      "         2.9433,  1.4306,  1.7624,  0.8747, -0.2810, -0.4489, -0.8126]) \t 6\n",
      "31. tensor([-2.4555, -1.1306, -2.3506, -1.0816,  0.2259,  3.2332,  2.4619,  1.1575,\n",
      "         3.3198,  1.5847,  1.0737,  0.3536, -0.2402, -0.5709, -0.5125]) \t 6\n",
      "32. tensor([ 7.4614, 10.5380,  8.6669, -0.8700, -2.3599, -1.8921, -2.9059,  0.0810,\n",
      "        -1.6769, -0.3088, -0.9029, -1.1065, -1.4689, -1.6036, -1.7077]) \t 1\n",
      "33. tensor([-1.8362, -1.9618, -5.3983, -4.8628, -2.9627,  0.1340,  2.7635,  3.9229,\n",
      "         4.8287,  4.2775,  3.9535,  3.8709,  1.1132,  1.6847,  1.3879]) \t 8\n",
      "34. tensor([ -1.5922,  -1.8137,  -5.2269,  -6.9135, -10.0297,  -6.2892,  -1.7048,\n",
      "          3.5673,   4.5296,   6.4013,   7.3016,   7.5528,   6.0494,   7.6760,\n",
      "          6.2026]) \t 10\n",
      "35. tensor([ -2.0359,  -2.4501,  -7.6267,  -7.6400, -10.5120,  -6.1741,  -2.1892,\n",
      "          5.5467,   4.9065,   7.0659,  10.2047,   9.5783,   6.8056,   9.9021,\n",
      "          7.0435]) \t 10\n",
      "36. tensor([-2.9024, -1.9109, -1.6394,  0.5624,  1.3185,  2.5824,  5.4621,  4.2977,\n",
      "         1.3470,  1.0551,  0.8256, -0.1515, -0.2214, -1.2226, -0.6235]) \t 6\n",
      "37. tensor([-3.7573, -0.7882,  0.1983,  6.8558,  3.8828,  4.6163,  2.5192, -1.8681,\n",
      "         2.4453, -0.0723, -1.3956, -2.6920, -2.9952, -4.6863, -3.2019]) \t 3\n",
      "38. tensor([-3.4784,  1.9965,  7.8982,  9.7098,  6.0726, -0.2367, -1.7934,  0.7940,\n",
      "        -3.0853, -1.7996, -3.1115, -2.8154, -3.0930, -4.3820, -3.2592]) \t 3\n",
      "39. tensor([-3.4704, -0.4532,  4.2362,  5.7536,  3.6188,  2.5481,  1.8466,  0.0487,\n",
      "        -0.3444, -0.7968, -2.0097, -3.0623, -2.3449, -4.1179, -2.9397]) \t 2\n",
      "40. tensor([ 5.4337,  9.6866,  8.2309,  2.9309, -0.4150, -5.6941, -6.3708, -3.0979,\n",
      "        -3.1690, -0.4765, -1.5692, -1.0342, -1.6196, -1.9028, -1.6993]) \t 1\n",
      "41. tensor([-0.2837,  5.2069, 10.1824,  6.6638,  3.5575, -3.5710, -1.7646,  0.1926,\n",
      "        -2.8325, -1.1561, -3.5404, -3.3207, -3.0104, -4.7223, -3.4944]) \t 3\n",
      "42. tensor([-2.3077, -2.0109, -4.0910, -3.3214, -1.3699,  3.3878,  5.0666,  5.5037,\n",
      "         2.8504,  2.5378,  2.2899,  1.3675, -0.1922, -1.0126, -0.7759]) \t 6\n",
      "43. tensor([-2.5073, -2.9500, -4.6551, -4.3300, -2.2537,  0.8499,  2.8588,  3.5665,\n",
      "         4.6162,  4.8150,  3.2998,  3.2742,  1.0860,  1.1509,  0.9943]) \t 8\n",
      "44. tensor([22.9971, 19.8735,  6.6568, -8.4170, -9.7350, -6.0268, -5.9089,  0.7960,\n",
      "        -1.6262, -0.0964,  1.0165,  1.2759, -1.1327, -0.1071, -1.0508]) \t 0\n",
      "45. tensor([ 1.5393,  6.1150,  6.8683,  4.1238,  0.9960, -0.6896, -5.0091, -1.9403,\n",
      "        -2.7618, -1.3859, -1.5920, -1.3186, -1.3236, -1.5641, -1.4625]) \t 1\n",
      "46. tensor([ 1.1273,  4.6751,  6.9414,  3.9314,  1.3948, -2.3113, -3.9282, -1.8119,\n",
      "        -1.8969, -0.9895, -1.4492, -1.3437, -1.3437, -1.7032, -1.3024]) \t 1\n",
      "47. tensor([-3.4570, -4.4664, -8.7738, -7.5486, -8.5992, -4.7470,  2.2265,  7.2760,\n",
      "         7.4787, 10.0965,  8.3386,  8.4933,  4.1215,  4.3047,  4.4461]) \t 10\n",
      "48. tensor([ 7.3590, 11.2466, 10.1842,  1.1712, -3.1328, -4.8764, -3.1359, -0.0355,\n",
      "        -2.8215, -1.0500, -1.5289, -1.2101, -1.6442, -2.1914, -2.0036]) \t 1\n",
      "49. tensor([-3.1888, -0.5598,  1.9789,  5.8942,  3.8581,  1.8515,  0.9010, -0.0823,\n",
      "        -0.2885, -0.8998, -1.6822, -2.1840, -1.9452, -3.0781, -2.1196]) \t 3\n",
      "50. tensor([15.3083, 15.5352,  7.3441, -3.3311, -5.1854, -3.6907, -6.6956,  0.4524,\n",
      "        -2.2735,  0.3156,  0.1134,  0.3378, -1.0521, -1.1556, -1.4875]) \t 1\n",
      "51. tensor([-2.7914,  3.2757,  5.3325,  4.1582,  4.9999,  2.0200, -4.5138, -1.9416,\n",
      "        -2.1484, -0.3292, -0.8378, -0.7136, -1.4737, -1.9832, -1.6624]) \t 4\n",
      "52. tensor([ 20.9042,  22.0588,  10.0100,  -3.3209, -10.6287,  -7.6413,  -8.7829,\n",
      "         -1.8702,  -2.8162,  -0.8570,   0.2439,  -0.0593,  -1.5046,  -0.8567,\n",
      "         -1.6866]) \t 0\n",
      "53. tensor([-1.5622,  7.0448, 11.7807,  7.3045,  0.7971, -1.2102, -3.6509, -1.5121,\n",
      "        -4.8203, -2.5114, -2.7791, -2.8128, -2.3286, -3.1367, -2.5707]) \t 2\n",
      "54. tensor([-1.3647,  1.8331,  6.1090,  7.0705,  1.9542, -1.2182, -1.6280, -2.0836,\n",
      "        -1.9217, -1.6591, -2.0188, -2.3848, -1.8532, -2.7247, -1.9552]) \t 2\n",
      "55. tensor([-0.5783,  6.9385, 13.8263,  9.0457,  1.0396, -5.3750, -5.9383, -2.7998,\n",
      "        -4.6457, -1.5162, -3.2610, -2.8954, -2.3758, -3.3790, -2.7557]) \t 2\n",
      "56. tensor([-1.0853, -1.3383, -4.2680, -4.5603, -7.2007, -1.6014, -0.4328,  1.7925,\n",
      "         3.6612,  3.9700,  4.8198,  4.3374,  3.1147,  4.8701,  2.5581]) \t 8\n",
      "57. tensor([-1.1196, -1.1736, -3.1599, -1.7590,  0.0586,  1.0896,  1.2636,  2.1202,\n",
      "         2.6117,  1.7239,  1.8542,  1.4411,  0.4653,  0.7148,  0.2207]) \t 8\n",
      "58. tensor([-1.2156,  1.3532,  4.7585,  2.0417,  0.7618, -0.4275, -0.0196,  0.2507,\n",
      "        -0.6422,  1.2197, -1.0061, -1.1818, -1.0775, -2.5397, -1.7193]) \t 2\n",
      "59. tensor([ 6.4897,  9.7183,  7.8625,  1.9711, -3.5044, -7.1198, -5.6530, -2.3408,\n",
      "        -1.5618, -0.6554, -0.5864, -0.1980, -1.0693, -0.7587, -1.0454]) \t 2\n",
      "60. tensor([-2.3800, -2.1460, -2.4649, -0.5567,  0.4348,  3.8660,  3.8787,  2.3377,\n",
      "         1.9754,  1.3795,  0.8589,  0.1748, -0.3845, -1.4998, -0.7676]) \t 6\n",
      "61. tensor([-2.9209, -1.5562,  0.2961,  0.5071,  0.9883,  4.2014,  3.5580,  1.9940,\n",
      "        -0.0666,  1.4118, -0.1619, -1.1117, -0.7668, -2.2644, -1.5023]) \t 5\n",
      "62. tensor([12.9153, 16.1623,  9.5680, -0.9114, -0.9648, -6.0005, -9.1360, -1.3828,\n",
      "        -2.4022,  0.0626, -0.1201,  0.0280, -1.4593, -0.9436, -1.4696]) \t 1\n",
      "63. tensor([-2.7635, -2.7575, -3.8593, -0.5068, -0.7647,  1.0341,  4.0177,  3.0308,\n",
      "         3.9232,  4.0225,  2.2441,  1.1906,  0.2245, -1.0331, -0.2921]) \t 7\n",
      "64. tensor([-3.9037,  1.3734,  5.5053,  8.7385,  4.9094,  1.7741, -1.2121, -1.8351,\n",
      "        -2.6284, -2.7806, -2.4888, -2.4064, -2.2797, -2.6532, -2.2062]) \t 3\n",
      "65. tensor([-2.9141, -2.4302, -2.5730,  0.1974,  1.0782,  5.1165,  6.0473,  2.9184,\n",
      "         2.2561,  0.4523,  0.6560, -1.3963, -1.6690, -2.5512, -1.9859]) \t 5\n",
      "66. tensor([-2.3636, -2.2738, -3.7031, -0.3356,  0.4459,  1.5176,  3.7943,  3.9760,\n",
      "         3.3388,  2.3130,  1.4791,  0.9898, -0.1909, -0.6670, -0.3141]) \t 6\n",
      "67. tensor([-2.1417,  2.3286,  8.2203,  6.5407,  1.8426,  1.0424, -2.4605, -2.2075,\n",
      "        -3.2648, -1.2690, -2.0771, -2.6751, -1.6342, -2.9677, -2.2576]) \t 2\n",
      "68. tensor([-2.5902, -3.0400, -8.7281, -5.8573, -5.0475, -0.4814,  1.9435,  4.1766,\n",
      "         6.5763,  7.0278,  6.5362,  6.8116,  2.9922,  4.6210,  3.6853]) \t 9\n",
      "69. tensor([-1.5081, -1.2364, -4.1181, -4.3896, -1.0459, -0.0470,  1.0785,  3.0003,\n",
      "         4.2558,  3.7978,  4.0415,  3.6299,  1.5995,  1.8175,  0.8406]) \t 8\n",
      "70. tensor([-4.2630, -1.7826,  0.0114,  1.4040,  4.6255,  5.7627,  5.6589,  3.3964,\n",
      "         0.3319,  0.9131, -1.3367, -1.9261, -2.0636, -4.2043, -2.6136]) \t 5\n",
      "71. tensor([-3.0382, -3.1335, -6.1955, -1.6561,  1.3179,  1.8086,  4.0893,  3.4607,\n",
      "         5.6197,  3.7606,  3.0291,  2.2415,  0.1820, -0.2596,  0.0903]) \t 8\n",
      "72. tensor([-4.7602, -1.7199,  0.5601,  0.0655,  3.2525,  6.5521,  5.5818,  3.2702,\n",
      "        -0.6061,  2.2189, -0.5574, -1.5677, -1.2658, -4.1186, -2.8662]) \t 5\n",
      "73. tensor([-4.1729,  0.3030,  4.8473,  7.1093,  5.4913,  1.5209,  1.1036, -0.9558,\n",
      "        -1.9000, -1.5192, -2.6119, -3.0887, -2.5423, -3.6663, -2.6478]) \t 3\n",
      "74. tensor([-1.4780, -1.4595, -3.3564, -1.4136,  0.2203,  2.3885,  2.7051,  4.2682,\n",
      "         2.6227,  1.9868,  1.7002,  1.5753, -0.3879, -0.6424, -0.5070]) \t 6\n",
      "75. tensor([ 0.2832,  8.5761, 13.2933,  6.7431,  2.1408, -2.7954, -7.8533, -5.0152,\n",
      "        -3.7304, -2.2390, -2.3456, -2.4340, -1.8836, -2.2772, -2.1328]) \t 3\n",
      "76. tensor([ 5.2976,  6.1164,  3.6357, -1.2542, -1.0887, -0.5438, -1.1892,  1.1751,\n",
      "        -1.0313, -0.0693, -0.3848, -0.3075, -0.8976, -1.0989, -1.2124]) \t 1\n",
      "77. tensor([ 0.3567,  5.9496, 10.4719,  3.9567,  1.6182, -0.7096, -3.3182, -2.7947,\n",
      "        -4.4291, -1.4938, -2.3059, -2.5594, -1.8545, -2.8391, -2.3338]) \t 2\n",
      "78. tensor([-2.2543e+00, -2.3810e+00, -3.1773e+00, -1.9059e-01,  1.5351e+00,\n",
      "         3.2093e+00,  4.6735e+00,  3.7038e+00,  2.6706e+00,  1.2199e+00,\n",
      "         6.6357e-01, -1.5402e-03, -1.1033e+00, -2.1670e+00, -1.5545e+00]) \t 6\n",
      "79. tensor([-2.6156, -0.8369,  2.7986,  7.1360,  2.9255,  1.4014,  2.4086,  1.4792,\n",
      "        -1.2565, -1.5223, -2.5189, -2.7771, -2.3110, -3.9922, -2.6022]) \t 3\n",
      "80. tensor([ 0.6348,  6.6734, 11.7599,  7.7120,  1.5283, -3.3985, -6.0411, -3.4537,\n",
      "        -3.2852, -1.5719, -2.5383, -2.3797, -2.2242, -2.7555, -2.2584]) \t 2\n",
      "81. tensor([ 6.2743,  9.2822,  7.7178,  1.0597, -3.8352, -5.4577, -4.3420, -0.9723,\n",
      "        -1.8252, -0.4089, -0.4150, -0.7096, -1.0153, -1.1002, -1.1465]) \t 2\n",
      "82. tensor([ 4.9963,  7.7970,  4.8240,  0.6766, -1.4428, -1.2025, -2.5218, -0.1059,\n",
      "        -2.2129, -0.3237, -0.4675, -0.6414, -1.2992, -1.7464, -1.5350]) \t 1\n",
      "83. tensor([-6.4105, -1.0217,  2.8136,  5.7578,  6.5530,  7.2409,  4.7845,  2.0268,\n",
      "        -1.3435, -0.3846, -2.8932, -3.9509, -3.0064, -5.9400, -4.2230]) \t 4\n",
      "84. tensor([-2.9232, -3.0994, -5.0585, -4.0561, -3.6427, -0.8209,  3.1673,  5.0148,\n",
      "         5.8629,  5.8820,  4.3119,  4.3497,  1.6977,  1.6670,  1.3317]) \t 9\n",
      "85. tensor([ 0.7506,  4.4558,  6.8348,  4.0343,  0.2941, -1.7649, -1.7298, -1.4982,\n",
      "        -1.5994, -0.9252, -1.7961, -1.5930, -1.6314, -2.1501, -1.7488]) \t 2\n",
      "86. tensor([-1.8365, -1.5845, -4.6725, -3.3912, -4.1654,  0.0642,  3.0369,  2.8980,\n",
      "         3.8597,  2.7803,  3.6730,  2.6403,  1.2309,  1.6246,  1.7367]) \t 9\n",
      "87. tensor([ 3.4572,  8.1610,  8.3186,  1.8599,  0.6910, -1.3236, -4.6883, -0.8602,\n",
      "        -2.1539, -1.4422, -0.9688, -1.0687, -1.7455, -1.9117, -1.8396]) \t 1\n",
      "88. tensor([-1.6382, -1.3910, -2.0321, -1.3965, -0.6586,  1.5038,  3.0111,  2.4190,\n",
      "         2.3925,  0.9072,  1.4440,  0.7297,  0.0162, -0.1634, -0.0866]) \t 7\n",
      "89. tensor([-2.3539, -1.4787, -2.6377, -0.2961,  1.2941,  2.5646,  3.2416,  2.7413,\n",
      "         2.5870,  2.1306,  0.8069,  0.4829, -0.8178, -1.2526, -0.5113]) \t 4\n",
      "90. tensor([-2.3048,  0.5376,  3.9645,  8.4863,  3.6844, -0.5830, -0.2934,  0.1008,\n",
      "        -1.5085, -0.8774, -1.9697, -1.8529, -2.5039, -3.4725, -2.4410]) \t 3\n",
      "91. tensor([-4.0637, -1.2490, -1.0328,  4.6907,  4.0631,  6.9411,  2.1968,  1.6847,\n",
      "         0.0757, -1.5958, -0.3670, -1.7254, -1.7692, -2.6994, -2.1319]) \t 5\n",
      "92. tensor([-1.8216, -1.4392, -4.4347, -4.4861, -7.3901, -2.6387,  0.5784,  4.4220,\n",
      "         3.8904,  5.5107,  5.8695,  5.8285,  3.3853,  3.5912,  2.6115]) \t 9\n",
      "93. tensor([ 2.5790, 10.1604, 11.6331,  5.0788, -1.6546, -1.7745, -6.7462, -4.7019,\n",
      "        -3.8464, -1.0673, -1.5901, -2.0275, -1.7301, -2.5153, -2.2089]) \t 2\n",
      "94. tensor([ -2.3680,  -2.9061,  -6.6834,  -8.1112, -10.1498,  -7.5702,  -1.4598,\n",
      "          3.0821,   6.3329,   7.8923,   8.6292,   8.5834,   6.6203,   7.4096,\n",
      "          6.4135]) \t 11\n",
      "95. tensor([-0.9769, -0.8937, -3.3345, -2.4417, -3.1351,  0.1072,  0.6318,  2.9811,\n",
      "         2.7453,  3.1150,  3.0973,  2.6547,  0.8881,  1.1066,  0.8444]) \t 8\n",
      "96. tensor([-4.3614, -0.8788, -1.1216,  6.0668,  8.0708,  3.8589,  2.0899,  1.7617,\n",
      "         2.1295,  0.0234, -1.3638, -1.1901, -3.0283, -4.0504, -2.8595]) \t 4\n",
      "97. tensor([-1.4739, -1.4070, -2.8799, -2.2850, -3.2925, -0.1186,  1.9495,  3.0028,\n",
      "         1.6005,  2.7903,  2.2726,  2.1720,  1.4422,  1.2574,  0.5806]) \t 7\n",
      "98. tensor([-1.8882, -2.2322, -3.3558, -1.7754, -0.2537,  0.1850,  1.5602,  1.2789,\n",
      "         4.1759,  4.2970,  2.4964,  2.0934,  0.7691, -0.3249,  0.3767]) \t 8\n",
      "99. tensor([ 1.0567,  6.1856,  8.9259,  4.8689,  1.7437, -1.4370, -4.5881, -3.6660,\n",
      "        -2.4041, -1.9976, -2.1461, -2.3126, -1.9135, -2.1547, -1.9322]) \t 2\n",
      "100. tensor([-3.3724, -2.2672,  0.0984, -2.0994, -1.3406,  4.2125,  5.7486,  2.9959,\n",
      "         0.9731,  1.1939,  1.2915, -0.6510, -0.0372, -1.5301, -0.9489]) \t 5\n",
      "101. tensor([-0.5639,  5.1301, 10.0727,  8.3857,  1.6781, -1.9863, -4.2748, -2.1156,\n",
      "        -4.3082, -2.1981, -2.9125, -2.6918, -2.1417, -3.2644, -2.5644]) \t 2\n",
      "102. tensor([-0.8019,  3.5425,  8.7091,  6.8684, -1.2529, -0.5601, -1.4924, -1.2723,\n",
      "        -2.7546, -2.3196, -1.7885, -3.0692, -1.6361, -2.3832, -2.0531]) \t 3\n",
      "103. tensor([-3.1999e+00, -1.4723e+00, -1.0566e+00,  4.1538e+00,  5.6802e+00,\n",
      "         2.9565e+00,  1.7286e+00,  2.8007e+00,  8.8568e-01, -5.7892e-04,\n",
      "        -4.5408e-01, -1.4742e-01, -1.7345e+00, -2.2204e+00, -1.7977e+00]) \t 4\n",
      "104. tensor([13.1507, 11.6081,  4.4510, -5.1173, -3.6941, -5.4379, -4.5087,  0.5663,\n",
      "        -0.1963,  0.3373,  1.0444,  0.8165, -0.5944, -0.1397, -0.7183]) \t 0\n",
      "105. tensor([-3.1093e+00, -2.2738e-03,  3.3690e+00,  5.1376e+00,  3.9869e+00,\n",
      "         1.6879e+00,  1.2163e+00,  2.0655e+00, -2.1234e+00, -1.3372e+00,\n",
      "        -1.6609e+00, -1.5416e+00, -1.7131e+00, -2.8422e+00, -2.1224e+00]) \t 3\n",
      "106. tensor([-4.2824, -1.9042,  2.1628, -1.5957,  3.8803,  6.6878,  6.2371,  4.3505,\n",
      "        -1.9889,  3.1314, -1.3266, -1.8064, -0.7004, -4.6267, -3.3114]) \t 6\n",
      "107. tensor([ 1.5197e+01,  1.3960e+01,  4.0297e+00, -5.5549e+00, -4.3151e+00,\n",
      "        -4.6823e+00, -5.8231e+00, -1.7002e-01, -1.0720e+00, -1.0436e-02,\n",
      "         4.2895e-01,  8.4561e-01, -8.5828e-01, -4.1229e-01, -1.0313e+00]) \t 0\n",
      "108. tensor([11.1619, 13.4404,  9.7154,  0.3637,  1.3551, -5.3406, -9.3949, -2.8280,\n",
      "        -3.0103, -0.9297, -0.4030, -0.3768, -1.6518, -1.2817, -1.6360]) \t 0\n",
      "109. tensor([-2.9569, -1.0647,  1.8887,  2.0592,  3.8084,  3.5471,  2.2266,  2.0247,\n",
      "        -0.8097,  0.9685, -1.1863, -1.4835, -1.2406, -3.0092, -2.1119]) \t 5\n",
      "110. tensor([-2.5652, -1.3566,  1.0708,  3.9603,  2.8312,  2.4781,  1.7584,  1.0599,\n",
      "        -0.1196, -0.3330, -1.1051, -1.4025, -1.5877, -2.4826, -1.7278]) \t 3\n",
      "111. tensor([-2.2718,  3.5570,  8.3943,  9.2283,  1.6181, -0.6935, -4.2548, -2.1069,\n",
      "        -3.1741, -2.1488, -2.1436, -1.9922, -2.2431, -2.8379, -2.2105]) \t 3\n",
      "112. tensor([-5.7809, -4.4599, -2.0763, -0.0466,  8.5264,  9.2507,  4.6507, -0.2967,\n",
      "         6.2996,  3.4655,  1.4269, -0.9489, -3.0417, -5.8148, -3.5741]) \t 7\n",
      "113. tensor([ 0.8676,  7.3972, 10.1507,  4.4000,  2.0037, -1.1888, -3.8074, -2.4493,\n",
      "        -1.4747, -1.6370, -1.7527, -3.0183, -2.4023, -3.1726, -2.6135]) \t 1\n",
      "114. tensor([-0.2603,  4.7257,  9.7065,  1.9124,  6.1291,  2.9938, -6.0396, -5.1993,\n",
      "        -2.9994,  0.8146, -2.0366, -2.1563, -1.7816, -3.1643, -2.5891]) \t 2\n",
      "115. tensor([ -1.9021,  -2.5476,  -6.7849,  -7.0149, -10.5890,  -4.6101,   0.0632,\n",
      "          5.0602,   4.6579,   5.0788,   8.5645,   7.2858,   6.4921,   7.4581,\n",
      "          4.9299]) \t 11\n",
      "116. tensor([-4.1059,  0.6181,  4.6968,  6.0069,  3.9999,  3.0596, -0.5921, -1.3844,\n",
      "        -1.0786, -0.6233, -1.5570, -2.0531, -2.0279, -3.2848, -2.5521]) \t 4\n",
      "117. tensor([-2.0562, -1.0674, -0.0730,  3.7955,  3.3394,  2.3511,  1.2969,  0.0169,\n",
      "         0.4960, -0.0737, -0.6200, -1.4043, -1.3981, -2.4551, -1.5997]) \t 3\n",
      "118. tensor([-2.3224, -1.7674, -3.0717, -1.2435,  1.4787,  2.9686,  2.9216,  4.6616,\n",
      "         3.2232,  1.9160,  1.6958,  1.4088, -1.0205, -1.1548, -0.7112]) \t 6\n",
      "119. tensor([-2.3358, -1.3938, -1.1069, -0.9558,  1.2147,  5.3043,  4.6226,  0.9526,\n",
      "         2.0669,  1.0917,  1.0272, -1.2753, -0.9387, -2.0107, -1.4224]) \t 6\n",
      "120. tensor([-1.9658, -2.2510, -5.1944, -4.6870, -5.8234, -2.6856, -0.8692,  2.8298,\n",
      "         4.7879,  5.8799,  5.2224,  5.3896,  2.5749,  4.0530,  3.1212]) \t 8\n",
      "121. tensor([-4.0339e+00,  3.6375e-01,  4.9019e+00,  9.3757e+00,  3.9686e+00,\n",
      "         1.8992e+00,  1.9940e+00, -3.4778e-03, -1.4571e+00, -2.0610e+00,\n",
      "        -3.0238e+00, -3.3589e+00, -3.1957e+00, -5.2106e+00, -3.3527e+00]) \t 2\n",
      "122. tensor([-2.1768, -2.3971, -7.7164, -7.8055, -7.7706, -5.6358, -2.8884,  2.4947,\n",
      "         6.0350,  7.7603,  9.0965,  9.7485,  6.3854,  9.6336,  6.8759]) \t 13\n",
      "123. tensor([-1.9196, -2.1549, -4.8590, -3.4801, -3.4223, -0.8770,  0.5530,  3.4591,\n",
      "         4.5886,  5.4693,  4.7283,  4.0390,  2.2579,  2.2593,  1.3268]) \t 7\n",
      "124. tensor([-3.4859, -0.4536,  1.3045,  3.4497,  3.7868,  3.8328,  1.1797,  1.9954,\n",
      "        -0.8647, -0.2087, -0.4235, -0.5069, -1.3720, -2.2327, -1.9182]) \t 3\n",
      "125. tensor([-2.6710,  3.6330,  9.3258,  9.7647,  4.7933, -3.5937, -3.3871, -2.9225,\n",
      "        -3.1197, -2.3874, -3.1380, -2.8542, -2.4103, -3.2874, -2.4670]) \t 2\n",
      "126. tensor([-2.1372, -2.1921, -4.0634, -0.6683,  2.3293,  2.8988,  3.4262,  4.0225,\n",
      "         3.3684,  2.4671,  1.8900,  1.3960, -0.9967, -1.5352, -1.0186]) \t 9\n",
      "127. tensor([-2.5377, -2.7836, -6.2291, -1.7188, -0.9016,  2.1196,  3.5353,  4.7418,\n",
      "         5.0743,  1.9532,  3.3967,  2.5354,  0.8831,  0.9202,  0.5341]) \t 8\n",
      "128. tensor([ 0.1124,  3.1786,  6.2099,  2.9281,  0.5719, -1.1635, -0.3716, -1.3120,\n",
      "        -1.7156, -0.5782, -1.8739, -2.1506, -1.2520, -2.5619, -1.8256]) \t 2\n",
      "129. tensor([-2.6448,  1.9554,  6.1319,  8.3701,  5.0039,  1.3324, -2.4237, -3.0438,\n",
      "        -1.5283, -2.2005, -2.5482, -2.6141, -2.5900, -3.2820, -2.3640]) \t 2\n",
      "130. tensor([-2.1975, -2.1879, -3.7565,  0.0716,  2.0630,  1.0813,  3.8982,  4.0477,\n",
      "         3.0965,  1.4992,  0.9884,  0.9758, -0.5017, -0.9859, -0.8474]) \t 7\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(X_test):\n",
    "        y_val = model.forward(data)\n",
    "\n",
    "        print (f'{i+1}. {str(y_val)} \\t {y_test[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(y_true, y_pred):\n",
    "   \n",
    "   \n",
    "    _, predicted = torch.max(y_pred, 1)\n",
    "    \n",
    "    \n",
    "    correct = (predicted == y_true).sum().item()\n",
    "    total = y_true.size(0)\n",
    "    accuracy = correct / total\n",
    "    \n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.8015414258188824\n",
      "Testing Accuracy: 0.5153846153846153\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with torch.no_grad():\n",
    "    y_pred_train = model(X_train)\n",
    "    train_accuracy = calculate_accuracy(y_train, y_pred_train)\n",
    "    print(\"Training Accuracy:\", train_accuracy)\n",
    "\n",
    "    y_pred_test = model(X_test)\n",
    "    test_accuracy = calculate_accuracy(y_test, y_pred_test)\n",
    "    print(\"Testing Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def mean_squared_error(y_true, y_pred):\n",
    "    \n",
    "    mse = torch.mean((y_true - y_pred)**2).item()\n",
    "    return mse\n",
    "\n",
    "def mean_absolute_error(y_true, y_pred):\n",
    "   \n",
    "    mae = torch.mean(torch.abs(y_true - y_pred)).item()\n",
    "    return mae\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of y_true: torch.Size([130])\n",
      "Shape of y_pred: torch.Size([130, 15])\n",
      "Shape of y_true: tensor([325.])\n",
      "Shape of y_pred: tensor([[146., 146.,  68.,  26., 354., 193., 193.,  51., 121., 230., 230., 230.,\n",
      "         230., 230., 230.]])\n",
      "Training MSE: 28404.19921875\n",
      "Training MAE: 150.3333282470703\n",
      "Testing MSE: 8436.3330078125\n",
      "Testing MAE: 80.5999984741211\n"
     ]
    }
   ],
   "source": [
    "# After training the model\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_pred_train = model(X_train)\n",
    "    #mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "    #mae_train = mean_absolute_error(y_train, y_pred_train)\n",
    "    #print(\"Training MSE:\", mse_train)\n",
    "    #print(\"Training MAE:\", mae_train)\n",
    "\n",
    "    y_pred_test = model(X_test)\n",
    "    #mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "    #mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "    #print(\"Testing MSE:\", mse_test)\n",
    "    #print(\"Testing MAE:\", mae_test)\n",
    "\n",
    "    print(\"Shape of y_true:\", y_test.size())\n",
    "    print(\"Shape of y_pred:\", y_pred_test.size())\n",
    "\n",
    "    y_true_indextrain = torch.argmax(y_train.unsqueeze(dim=0), dim=1).float()\n",
    "    y_pred_indextrain = torch.argmax(y_pred_train.unsqueeze(dim=0), dim=1).float()\n",
    "\n",
    "    y_true_indextest = torch.argmax(y_test.unsqueeze(dim=0), dim=1).float()\n",
    "    y_pred_indextest = torch.argmax(y_pred_test.unsqueeze(dim=0), dim=1).float()\n",
    "\n",
    "    print(\"Shape of y_true:\", y_true_indextrain)\n",
    "    print(\"Shape of y_pred:\", y_pred_indextrain)\n",
    "    mse_train = mean_squared_error(y_true_indextrain, y_pred_indextrain)\n",
    "    mae_train = mean_absolute_error(y_true_indextrain, y_pred_indextrain)\n",
    "    print(\"Training MSE:\", mse_train)\n",
    "    print(\"Training MAE:\", mae_train)\n",
    "\n",
    "    mse_test = mean_squared_error(y_true_indextest, y_pred_indextest)\n",
    "    mae_test = mean_absolute_error(y_true_indextest, y_pred_indextest)\n",
    "    print(\"Testing MSE:\", mse_test)\n",
    "    print(\"Testing MAE:\", mae_test)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y_true and y_pred have different number of output (1!=15)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m y_pred_train \u001b[38;5;241m=\u001b[39m model(X_train)\n\u001b[1;32m----> 2\u001b[0m r2 \u001b[38;5;241m=\u001b[39m \u001b[43mr2_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true_indextest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred_indextest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mR-squared:\u001b[39m\u001b[38;5;124m\"\u001b[39m, r2)\n",
      "File \u001b[1;32mc:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1180\u001b[0m, in \u001b[0;36mr2_score\u001b[1;34m(y_true, y_pred, sample_weight, multioutput, force_finite)\u001b[0m\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[0;32m   1040\u001b[0m     {\n\u001b[0;32m   1041\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1059\u001b[0m     force_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   1060\u001b[0m ):\n\u001b[0;32m   1061\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\":math:`R^2` (coefficient of determination) regression score function.\u001b[39;00m\n\u001b[0;32m   1062\u001b[0m \n\u001b[0;32m   1063\u001b[0m \u001b[38;5;124;03m    Best possible score is 1.0 and it can be negative (because the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1178\u001b[0m \u001b[38;5;124;03m    -inf\u001b[39;00m\n\u001b[0;32m   1179\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1180\u001b[0m     y_type, y_true, y_pred, multioutput \u001b[38;5;241m=\u001b[39m \u001b[43m_check_reg_targets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1181\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\n\u001b[0;32m   1182\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1183\u001b[0m     check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m   1185\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _num_samples(y_pred) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:113\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[0;32m    110\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m y_pred\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_true\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m y_pred\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m--> 113\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    114\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true and y_pred have different number of output (\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m!=\u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    115\u001b[0m             y_true\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], y_pred\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    116\u001b[0m         )\n\u001b[0;32m    117\u001b[0m     )\n\u001b[0;32m    119\u001b[0m n_outputs \u001b[38;5;241m=\u001b[39m y_true\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    120\u001b[0m allowed_multioutput_str \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_values\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muniform_average\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvariance_weighted\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: y_true and y_pred have different number of output (1!=15)"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred_train = model(X_train)\n",
    "r2 = r2_score(y_true_indextest.detach().numpy(), y_pred_indextest.detach().numpy())\n",
    "print(\"R-squared:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
